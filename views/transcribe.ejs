<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech-to-Text Transcription</title>
    <link rel="stylesheet" href="/css/style.css">
    <style>
        /* Styling for Transcription Box */
        .transcription-box {
            width: 80%;
            min-height: 150px;
            padding: 15px;
            margin: 10px auto;
            border: 2px solid #a991d4;
            background: #f4f1ff;
            font-size: 1.2em;
            border-radius: 8px;
            word-wrap: break-word;
            white-space: pre-wrap;
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);
            overflow-y: auto;
            max-height: 400px;
        }

        /* Summary Box */
        .summary-box {
            width: 80%;
            min-height: 100px;
            padding: 15px;
            margin: 10px auto;
            border: 2px solid #ffa500;
            background: #fff4e1;
            font-size: 1.1em;
            border-radius: 8px;
            word-wrap: break-word;
            white-space: pre-wrap;
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);
            overflow-y: auto;
            max-height: 300px;
        }

        /* Audio Wave Effect */
        .wave {
            width: 50px;
            height: 10px;
            background-color: #a991d4;
            margin: auto;
            display: none;
            animation: wave-animation 1.2s infinite alternate;
        }

        @keyframes wave-animation {
            from { transform: scaleY(0.5); }
            to { transform: scaleY(1.5); }
        }

        /* Button Styling */
        .btn {
            display: inline-block;
            padding: 10px 20px;
            font-size: 16px;
            margin: 10px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background 0.3s;
        }

        .btn-record {
            background-color: #6a5acd;
            color: white;
        }

        .btn-summary {
            background-color: #ffa500;
            color: white;
        }

        .btn-clear {
            background-color: #ff6961;
            color: white;
        }

        .btn-download {
            background-color: #4CAF50;
            color: white;
        }

        .btn:hover {
            opacity: 0.8;
        }

        /* Centering Content */
        .container {
            text-align: center;
            padding: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Speech-to-Text Transcription</h1>
        <p>Click the button and start speaking.</p>

        <div id="root"></div>

        <a href="/" class="btn">Back to Home</a>
    </div>

    <!-- Load React -->
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>

    <script>
        const { useState, useEffect, useRef } = React;

        function TranscriptionButton() {
            const [transcript, setTranscript] = useState("Waiting for speech...");
            const [isRecording, setIsRecording] = useState(false);
            const [summary, setSummary] = useState("");
            const [loading, setLoading] = useState(false);
            const recognitionRef = useRef(null);

            useEffect(() => {
                if (!window.SpeechRecognition && !window.webkitSpeechRecognition) {
                    alert("Your browser does not support speech recognition.");
                    return;
                }

                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                const recognition = new SpeechRecognition();

                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = "en-US";

                recognition.onresult = (event) => {
                    let finalTranscript = "";
                    for (let i = 0; i < event.results.length; i++) {
                        let result = event.results[i];
                        let sentence = result[0].transcript;

                        sentence = sentence.charAt(0).toUpperCase() + sentence.slice(1);
                        if (!sentence.endsWith(".")) sentence += ".";

                        finalTranscript += sentence + " ";
                    }
                    setTranscript(finalTranscript);
                };

                recognition.onerror = (event) => {
                    setTranscript("Error: " + event.error);
                };

                recognitionRef.current = recognition;
            }, []);

            const toggleRecording = () => {
                if (isRecording) {
                    recognitionRef.current.stop();
                    setIsRecording(false);
                    document.getElementById("wave").style.display = "none";
                } else {
                    recognitionRef.current.start();
                    setIsRecording(true);
                    setTranscript("Listening...");
                    document.getElementById("wave").style.display = "block";
                }
            };

            const generateSummary = async () => {
                if (!transcript || transcript === "Waiting for speech...") {
                    alert("No text available for summarization.");
                    return;
                }

                setLoading(true);

                try {
                    const response = await fetch("/transcribe/summarize", {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify({ transcript })
                    });

                    const data = await response.json();
                    if (!data.summary) throw new Error("No valid response from OpenAI.");
                    setSummary(data.summary);
                } catch (error) {
                    console.error("Summarization Error:", error);
                    setSummary("Error summarizing text.");
                } finally {
                    setLoading(false);
                }
            };

            const clearTranscript = () => {
                setTranscript("Waiting for speech...");
                setSummary("");
            };

            const downloadTranscript = () => {
                const blob = new Blob([transcript], { type: "text/plain" });
                const a = document.createElement("a");
                a.href = URL.createObjectURL(blob);
                a.download = "transcription.txt";
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
            };

            return React.createElement("div", null,
                React.createElement("button", { onClick: toggleRecording, className: "btn btn-record" }, isRecording ? "Stop Recording" : "Start Recording"),
                React.createElement("button", { onClick: generateSummary, className: "btn btn-summary", disabled: loading }, loading ? "Summarizing..." : "Summarize"),
                React.createElement("button", { onClick: clearTranscript, className: "btn btn-clear" }, "Clear"),
                React.createElement("button", { onClick: downloadTranscript, className: "btn btn-download" }, "Download"),
                React.createElement("div", { id: "output", className: "transcription-box" }, transcript),
                summary && React.createElement("div", { id: "summary", className: "summary-box" }, summary)
            );
        }

        ReactDOM.createRoot(document.getElementById("root")).render(React.createElement(TranscriptionButton));
    </script>
</body>
</html>
